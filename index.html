<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Crystal Docs 1.7.3">
<meta name="crystal_docs.project_version" content="main">
<meta name="crystal_docs.project_name" content="tensorflow_lite">



<link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/doc.js"></script>

  <meta name="repository-name" content="tensorflow_lite">
  <title>tensorflow_lite main</title>
  <script type="text/javascript">
  CrystalDocs.base_path = "";
  </script>
</head>
<body>

<svg class="hidden">
  <symbol id="octicon-link" viewBox="0 0 16 16">
    <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </symbol>
</svg>
<div class="sidebar">
  <div class="sidebar-header">
    <div class="search-box">
      <input type="search" class="search-input" placeholder="Search..." spellcheck="false" aria-label="Search">
    </div>

    <div class="project-summary">
      <h1 class="project-name">
        <a href="index.html">
          tensorflow_lite
        </a>
      </h1>

      <span class="project-version">
        main
      </span>
    </div>
  </div>

  <div class="search-results hidden">
    <ul class="search-list"></ul>
  </div>

  <div class="types-list">
    <ul>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite" data-name="tensorflowlite">
      <a href="TensorflowLite.html">TensorflowLite</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Client" data-name="tensorflowlite::client">
      <a href="TensorflowLite/Client.html">Client</a>
      
    </li>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Delegate" data-name="tensorflowlite::delegate">
      <a href="TensorflowLite/Delegate.html">Delegate</a>
      
    </li>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite/EdgeTPU" data-name="tensorflowlite::edgetpu">
      <a href="TensorflowLite/EdgeTPU.html">EdgeTPU</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/EdgeTPU/Delegate" data-name="tensorflowlite::edgetpu::delegate">
      <a href="TensorflowLite/EdgeTPU/Delegate.html">Delegate</a>
      
    </li>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite/EdgeTPU/Device" data-name="tensorflowlite::edgetpu::device">
      <a href="TensorflowLite/EdgeTPU/Device.html">Device</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/EdgeTPU/Device/Type" data-name="tensorflowlite::edgetpu::device::type">
      <a href="TensorflowLite/EdgeTPU/Device/Type.html">Type</a>
      
    </li>
  
</ul>

      
    </li>
  
</ul>

      
    </li>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite/Interpreter" data-name="tensorflowlite::interpreter">
      <a href="TensorflowLite/Interpreter.html">Interpreter</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Interpreter/InvokeError" data-name="tensorflowlite::interpreter::invokeerror">
      <a href="TensorflowLite/Interpreter/InvokeError.html">InvokeError</a>
      
    </li>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Interpreter/Status" data-name="tensorflowlite::interpreter::status">
      <a href="TensorflowLite/Interpreter/Status.html">Status</a>
      
    </li>
  
</ul>

      
    </li>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/InterpreterOptions" data-name="tensorflowlite::interpreteroptions">
      <a href="TensorflowLite/InterpreterOptions.html">InterpreterOptions</a>
      
    </li>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Model" data-name="tensorflowlite::model">
      <a href="TensorflowLite/Model.html">Model</a>
      
    </li>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite/Tensor" data-name="tensorflowlite::tensor">
      <a href="TensorflowLite/Tensor.html">Tensor</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Tensor/Type" data-name="tensorflowlite::tensor::type">
      <a href="TensorflowLite/Tensor/Type.html">Type</a>
      
    </li>
  
</ul>

      
    </li>
  
  <li class="parent " data-id="tensorflow_lite/TensorflowLite/Utilities" data-name="tensorflowlite::utilities">
      <a href="TensorflowLite/Utilities.html">Utilities</a>
      
        <ul>
  
  <li class=" " data-id="tensorflow_lite/TensorflowLite/Utilities/ExtractLabels" data-name="tensorflowlite::utilities::extractlabels">
      <a href="TensorflowLite/Utilities/ExtractLabels.html">ExtractLabels</a>
      
    </li>
  
</ul>

      
    </li>
  
</ul>

      
    </li>
  
</ul>

  </div>
</div>


<div class="main-content">
<h1><a id="tensorflow-lite" class="anchor" href="#tensorflow-lite">  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>tensorflow_lite</h1>
<p><a href="https://github.com/spider-gazelle/tensorflow_lite/actions/workflows/ci.yml"><img src="https://github.com/spider-gazelle/tensorflow_lite/actions/workflows/ci.yml/badge.svg" alt="CI" /></a> A library for running TF Lite models</p>
<ul>
<li>once you've trained a model in TensorFlow you can convert it to <a href="https://www.tensorflow.org/lite/models/convert/convert_models#command_line_tool_">TF Lite</a> for production use</li>
<li>inspect the TF Lite model using <a href="https://netron.app/">netron.app</a></li>
<li>some <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">good TF models</a> for object detection (need conversion)</li>
</ul>
<p>Also see the <a href="https://spider-gazelle.github.io/tensorflow_lite/TensorflowLite/Client.html">project documentation</a></p>
<h2><a id="installation" class="anchor" href="#installation">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>Installation</h2>
<ol>
<li>
<p>Add the dependency to your <code>shard.yml</code>:</p>
<pre><code class="language-yaml">dependencies:
  tensorflow_lite:
    github: spider-gazelle/tensorflow_lite</code></pre>
</li>
<li>
<p>Run <code>shards install</code></p>
</li>
</ol>
<h2><a id="usage" class="anchor" href="#usage">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>Usage</h2>
<p>See the specs for basic usage or have a look at <a href="https://github.com/stakach/imagine/blob/master/src/imagine/models/example_object_detection.cr">imagine</a></p>
<pre><code class="language-crystal"><span class="k">require</span> <span class="s">&quot;tensorflow_lite&quot;</span></code></pre>
<p>you can use the example metadata extractor to obtain the metadata for TF Lite models downloaded from <a href="https://tfhub.dev/s?deployment-format=lite">tfhub.dev</a></p>
<h3><a id="with-and-edge-tpu" class="anchor" href="#with-and-edge-tpu">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>With and EdgeTPU</h3>
<p>Such as a Coral USB device</p>
<pre><code class="language-crystal"><span class="k">require</span> <span class="s">&quot;tensorflow_lite/edge_tpu&quot;</span></code></pre>
<p>To install the edge tpu delegate:</p>
<pre><code class="language-bash"># Add Google Cloud public key
RUN wget -q -O - https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor &gt; /etc/apt/trusted.gpg.d/coral-edgetpu.gpg

# Add Coral packages repository
RUN echo &quot;deb [signed-by=/etc/apt/trusted.gpg.d/coral-edgetpu.gpg] https://packages.cloud.google.com/apt coral-edgetpu-stable main&quot; | tee /etc/apt/sources.list.d/coral-edgetpu.list

# install the lib
sudo apt update
sudo apt install libedgetpu-dev</code></pre>
<p>To install the <a href="https://coral.ai/docs/accelerator/get-started/#requirements">Coral USB drivers</a></p>
<pre><code class="language-bash">sudo apt install libedgetpu1-std
# OR for max frequency
sudo apt install libedgetpu1-max

# unplug and re-plug the coral or run this
sudo systemctl restart udev</code></pre>
<p><span class="flag purple">NOTE</span> : when using a coral and running <code>lsusb</code> you need to look for either:</p>
<ul>
<li>Global Unichip Corp.</li>
<li>Google Inc.</li>
</ul>
<p>after running something on the chip it will <a href="https://www.reddit.com/r/Proxmox/comments/nmsknx/proxmox_vm_ubuntu_2004_connect_google_coral_usb/">change identity to Google Inc.</a></p>
<p>And you need to include the Google identity version in any docker files.</p>
<h2><a id="development" class="anchor" href="#development">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>Development</h2>
<p>To update tensorflow lite bindings <code>./generate_bindings.sh</code></p>
<h3><a id="lib-installation" class="anchor" href="#lib-installation">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>lib installation</h3>
<p>Requires <a href="https://www.tensorflow.org/install/lang_c">libtensorflow</a> to be installed, this is handled automatically by <code>./build_tensorflowlite.sh</code></p>
<ul>
<li>there is a <a href="https://www.tensorflow.org/lite/guide/build_cmake">guide to building it</a></li>
<li>you can use <code>./build_tensorflowlite.sh</code> to automate this</li>
<li>then requires <code>export LD_LIBRARY_PATH=/usr/local/lib</code> to run</li>
<li>test if installed successfully <code>crystal ./src/tensorflow_lite.cr</code>
<ul>
<li>this will output <code>Launching with tensorflow lite vx.x.x</code></li>
</ul>
</li>
</ul>
<p><span class="flag purple">NOTE</span> : the lib is installed for local use via a postinstall script.
Make sure to distribute <code>libtensorflowlite_c.so</code> with your production app</p>
<h2><a id="contributing" class="anchor" href="#contributing">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>Contributing</h2>
<ol>
<li>Fork it (<a href="https://github.com/your-github-user/tensorflow_lite/fork">https://github.com/your-github-user/tensorflow_lite/fork</a>)</li>
<li>Create your feature branch (<code>git checkout -b my-new-feature</code>)</li>
<li>Commit your changes (<code>git commit -am 'Add some feature'</code>)</li>
<li>Push to the branch (<code>git push origin my-new-feature</code>)</li>
<li>Create a new Pull Request</li>
</ol>
<h2><a id="contributors" class="anchor" href="#contributors">
  <svg class="octicon-link" aria-hidden="true">
    <use href="#octicon-link"/>
  </svg>
</a>Contributors</h2>
<ul>
<li><a href="https://github.com/stakach">Stephen von Takach</a> - creator and maintainer</li>
</ul>
</div>
</body>
</html>
